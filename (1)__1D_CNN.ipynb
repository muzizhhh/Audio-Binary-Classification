{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME = \"Q2_Adam_DenseDropOut\"\n",
    "# tensorboard = TensorBoard(log_dir=\"1dCNN-{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import competition dataset\n",
    "x_train = np.load('train_data.npy')\n",
    "y_train = pd.read_csv('train_labels.csv')\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train[:,1]\n",
    "\n",
    "x_test = np.load('test_data.npy')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalization    \n",
    "#normalizer = Normalizer().fit(x_train)\n",
    "#x_train = normalizer.transform(x_train)\n",
    "#x_test = normalizer.transform(x_test)\n",
    "\n",
    "# reshape\n",
    "x_train = x_train.reshape(-1,x_train.shape[1],1)\n",
    "x_test = x_test.reshape(-1,x_test.shape[1],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output a 2 dim vector indicating class\n",
    "y_train = np_utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 00:17:25.924477  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 00:17:25.966012  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 00:17:25.971917  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 00:17:26.264611  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=50, strides=10)`\n",
      "  import sys\n",
      "W0924 00:17:26.325238  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=50, strides=10)`\n",
      "  del sys.path[0]\n",
      "W0924 00:17:26.863973  8420 deprecation.py:506] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# create 1-D CNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=5, \n",
    "                 activation='relu',\n",
    "                 input_shape=(x_train.shape[1],1))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=50,stride=10))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=50,stride=10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 44096, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44096, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4405, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 4401, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4401, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 436, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27904)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3571840   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 3,582,978\n",
      "Trainable params: 3,582,786\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 00:17:27.234030  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0924 00:17:27.247353  8420 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0924 00:17:27.257280  8420 deprecation.py:323] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "\n",
    "adam=optimizers.Adam(lr=.0001) \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "3599/3599 [==============================] - 610s 170ms/step - loss: 0.6055 - acc: 0.9130 - val_loss: 0.2024 - val_acc: 0.9525\n",
      "Epoch 2/30\n",
      "3599/3599 [==============================] - 747s 208ms/step - loss: 0.3458 - acc: 0.9433 - val_loss: 0.1336 - val_acc: 0.9725\n",
      "Epoch 3/30\n",
      "3599/3599 [==============================] - 602s 167ms/step - loss: 0.2231 - acc: 0.9572 - val_loss: 0.1389 - val_acc: 0.9700\n",
      "Epoch 4/30\n",
      "3599/3599 [==============================] - 34423s 10s/step - loss: 0.1866 - acc: 0.9600 - val_loss: 0.1083 - val_acc: 0.9750\n",
      "Epoch 5/30\n",
      "3599/3599 [==============================] - 613s 170ms/step - loss: 0.1595 - acc: 0.9650 - val_loss: 0.1292 - val_acc: 0.9650\n",
      "Epoch 6/30\n",
      "3599/3599 [==============================] - 654s 182ms/step - loss: 0.1688 - acc: 0.9628 - val_loss: 0.1246 - val_acc: 0.9800\n",
      "Epoch 7/30\n",
      "3599/3599 [==============================] - 640s 178ms/step - loss: 0.1314 - acc: 0.9722 - val_loss: 0.1141 - val_acc: 0.9725\n",
      "Epoch 8/30\n",
      "3599/3599 [==============================] - 639s 178ms/step - loss: 0.1215 - acc: 0.9703 - val_loss: 0.1063 - val_acc: 0.9825\n",
      "Epoch 9/30\n",
      "3599/3599 [==============================] - 634s 176ms/step - loss: 0.1242 - acc: 0.9714 - val_loss: 0.1179 - val_acc: 0.9775\n",
      "Epoch 10/30\n",
      "3599/3599 [==============================] - 641s 178ms/step - loss: 0.0943 - acc: 0.9775 - val_loss: 0.1353 - val_acc: 0.9775\n",
      "Epoch 11/30\n",
      "3599/3599 [==============================] - 611s 170ms/step - loss: 0.0930 - acc: 0.9761 - val_loss: 0.1434 - val_acc: 0.9700\n",
      "Epoch 12/30\n",
      "3599/3599 [==============================] - 543s 151ms/step - loss: 0.0813 - acc: 0.9783 - val_loss: 0.1423 - val_acc: 0.9750\n",
      "Epoch 13/30\n",
      "3599/3599 [==============================] - 307s 85ms/step - loss: 0.0962 - acc: 0.9797 - val_loss: 0.1720 - val_acc: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126dcab8d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "EarlyStopping = EarlyStopping(monitor='val_loss',patience=5,verbose=0,mode='auto')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.1,callbacks=[EarlyStopping]) #callbacks=[tensorboard]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "y_predict= model.predict_classes(x_test)\n",
    "print(y_predict[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_predict,columns=['label']).to_csv('submission_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TrainingNotes:\n",
    "# original //0.0583 - acc: 0.9825 - val_loss: 0.1250 - val_acc: 0.9650\n",
    "# add batchNormalization and dropout(0.5) on all conv layer and validation split=0.1 // not good\n",
    "* only add batchNormalization on conv //loss: 0.0962 - acc: 0.9797 - val_loss: 0.1720 - val_acc: 0.9725\n",
    "# 2nd convLayer from 64 to 128.and maxpooling 50 to 60 //loss: 0.2091 - acc: 0.9644 - val_loss: 0.1568 - val_acc: 0.9675\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
