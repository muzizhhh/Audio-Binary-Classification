{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D__CNN and DataEnhancement (pitch shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import competition dataset but downsampling to 3999*4410\n",
    "\n",
    "x_train = np.load('train_data.npy')\n",
    "y_train = pd.read_csv('train_labels.csv')\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train[:,1]\n",
    "\n",
    "x_test = np.load('test_data.npy')\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 44100)\n",
      "(3997, 44100)\n",
      "(3999, 44100, 1) (3997, 44100, 1) (3999,)\n"
     ]
    }
   ],
   "source": [
    "# DATA_ENHANCE_x_train\n",
    "\n",
    "array_ts = []\n",
    "for i in range(len(x_train)):\n",
    "    y_ts = librosa.effects.pitch_shift(x_train[i],x_train.shape[1], n_steps=3)\n",
    "    array_ts.append(y_ts)\n",
    "x_ts= np.vstack(array_ts)\n",
    "print(x_ts.shape)\n",
    "\n",
    "# DATA_ENHANCE___x_test\n",
    "\n",
    "array_tsTest = []\n",
    "for i in range(len(x_test)):\n",
    "    y_tsTest = librosa.effects.pitch_shift(x_test[i],x_test.shape[1], n_steps=3)\n",
    "    array_tsTest.append(y_tsTest)\n",
    "x_tsTest = np.vstack(array_tsTest)\n",
    "print(x_tsTest.shape)\n",
    "\n",
    "# reshape\n",
    "x_train = x_ts.reshape(-1,x_ts.shape[1],1)\n",
    "x_test = x_tsTest.reshape(-1,x_tsTest.shape[1],1)\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output a 2 dim vector indicating class\n",
    "y_train = np_utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1-D CNN\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=5, \n",
    "                 activation='relu',\n",
    "                 input_shape=(x_train.shape[1],1),\n",
    "                 kernel_regularizer=regularizers.l1(0.001))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=50,strides=10))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, \n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=regularizers.l1(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=50,strides=10))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, \n",
    "                 activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=50,strides=10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 44096, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 44096, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 4405, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 4401, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4401, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 436, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 432, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 432, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4992)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               639104    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 691,842\n",
      "Trainable params: 691,394\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "adam=optimizers.Adam(lr=.0001) \n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "3599/3599 [==============================] - 457s 127ms/step - loss: 0.9624 - acc: 0.9241 - val_loss: 0.7709 - val_acc: 0.9450\n",
      "Epoch 2/30\n",
      "3599/3599 [==============================] - 916s 255ms/step - loss: 0.7628 - acc: 0.9467 - val_loss: 0.7288 - val_acc: 0.9525\n",
      "Epoch 3/30\n",
      "3599/3599 [==============================] - 781s 217ms/step - loss: 0.7281 - acc: 0.9550 - val_loss: 0.7062 - val_acc: 0.9650\n",
      "Epoch 4/30\n",
      "3599/3599 [==============================] - 775s 215ms/step - loss: 0.6843 - acc: 0.9661 - val_loss: 0.6574 - val_acc: 0.9725\n",
      "Epoch 5/30\n",
      "3599/3599 [==============================] - 833s 231ms/step - loss: 0.6567 - acc: 0.9667 - val_loss: 0.6651 - val_acc: 0.9600\n",
      "Epoch 6/30\n",
      "3599/3599 [==============================] - 790s 219ms/step - loss: 0.6515 - acc: 0.9680 - val_loss: 0.6517 - val_acc: 0.9625\n",
      "Epoch 7/30\n",
      "3599/3599 [==============================] - 777s 216ms/step - loss: 0.6378 - acc: 0.9689 - val_loss: 0.6306 - val_acc: 0.9600\n",
      "Epoch 8/30\n",
      "3599/3599 [==============================] - 779s 217ms/step - loss: 0.6219 - acc: 0.9725 - val_loss: 0.6228 - val_acc: 0.9725\n",
      "Epoch 9/30\n",
      "3599/3599 [==============================] - 781s 217ms/step - loss: 0.6008 - acc: 0.9742 - val_loss: 0.6311 - val_acc: 0.9625\n",
      "Epoch 10/30\n",
      "3599/3599 [==============================] - 794s 221ms/step - loss: 0.5739 - acc: 0.9831 - val_loss: 0.6153 - val_acc: 0.9675\n",
      "Epoch 11/30\n",
      "3599/3599 [==============================] - 804s 224ms/step - loss: 0.5805 - acc: 0.9758 - val_loss: 0.6191 - val_acc: 0.9550\n",
      "Epoch 12/30\n",
      "3599/3599 [==============================] - 816s 227ms/step - loss: 0.5603 - acc: 0.9825 - val_loss: 0.6027 - val_acc: 0.9550\n",
      "Epoch 13/30\n",
      "3599/3599 [==============================] - 929s 258ms/step - loss: 0.5562 - acc: 0.9800 - val_loss: 0.5796 - val_acc: 0.9700\n",
      "Epoch 14/30\n",
      "3599/3599 [==============================] - 882s 245ms/step - loss: 0.5400 - acc: 0.9819 - val_loss: 0.5834 - val_acc: 0.9725\n",
      "Epoch 15/30\n",
      "3599/3599 [==============================] - 525s 146ms/step - loss: 0.5270 - acc: 0.9833 - val_loss: 0.5741 - val_acc: 0.9750\n",
      "Epoch 16/30\n",
      "3599/3599 [==============================] - 717s 199ms/step - loss: 0.5164 - acc: 0.9831 - val_loss: 0.5670 - val_acc: 0.9775\n",
      "Epoch 17/30\n",
      "3599/3599 [==============================] - 822s 228ms/step - loss: 0.5054 - acc: 0.9847 - val_loss: 0.5551 - val_acc: 0.9750\n",
      "Epoch 18/30\n",
      "3599/3599 [==============================] - 565s 157ms/step - loss: 0.4964 - acc: 0.9864 - val_loss: 0.5401 - val_acc: 0.9700\n",
      "Epoch 19/30\n",
      "3599/3599 [==============================] - 572s 159ms/step - loss: 0.4806 - acc: 0.9875 - val_loss: 0.5475 - val_acc: 0.9750\n",
      "Epoch 20/30\n",
      "3599/3599 [==============================] - 801s 222ms/step - loss: 0.4850 - acc: 0.9822 - val_loss: 0.5181 - val_acc: 0.9700\n",
      "Epoch 21/30\n",
      "3599/3599 [==============================] - 660s 183ms/step - loss: 0.4780 - acc: 0.9839 - val_loss: 0.5399 - val_acc: 0.9725\n",
      "Epoch 22/30\n",
      "3599/3599 [==============================] - 639s 178ms/step - loss: 0.4640 - acc: 0.9867 - val_loss: 0.5555 - val_acc: 0.9650\n",
      "Epoch 23/30\n",
      "3599/3599 [==============================] - 794s 221ms/step - loss: 0.4582 - acc: 0.9881 - val_loss: 0.4982 - val_acc: 0.9725\n",
      "Epoch 24/30\n",
      "3599/3599 [==============================] - 605s 168ms/step - loss: 0.4431 - acc: 0.9889 - val_loss: 0.5293 - val_acc: 0.9675\n",
      "Epoch 25/30\n",
      "3599/3599 [==============================] - 414s 115ms/step - loss: 0.4394 - acc: 0.9897 - val_loss: 0.5091 - val_acc: 0.9750\n",
      "Epoch 26/30\n",
      "3599/3599 [==============================] - 425s 118ms/step - loss: 0.4388 - acc: 0.9872 - val_loss: 0.5858 - val_acc: 0.9525\n",
      "Epoch 27/30\n",
      "3599/3599 [==============================] - 468s 130ms/step - loss: 0.4334 - acc: 0.9858 - val_loss: 0.4901 - val_acc: 0.9700\n",
      "Epoch 28/30\n",
      "3599/3599 [==============================] - 476s 132ms/step - loss: 0.4206 - acc: 0.9900 - val_loss: 0.4977 - val_acc: 0.9725\n",
      "Epoch 29/30\n",
      "3599/3599 [==============================] - 469s 130ms/step - loss: 0.4116 - acc: 0.9900 - val_loss: 0.5091 - val_acc: 0.9725\n",
      "Epoch 30/30\n",
      "3599/3599 [==============================] - 461s 128ms/step - loss: 0.4179 - acc: 0.9839 - val_loss: 0.4799 - val_acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186d48245c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "EarlyStopping = EarlyStopping(monitor='val_loss',patience=5,verbose=0,mode='auto')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.1,callbacks=[EarlyStopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_predict= model.predict_classes(x_test)\n",
    "print(y_predict[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_predict,columns=['label']).to_csv('submission_1dCNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"TrainingNote:\"\n",
    "// loss: 0.1601 - acc: 0.9372 - val_loss: 0.1614 - val_acc: 0.9475\n",
    "//loss: 0.2104 - acc: 0.9564 - val_loss: 0.1292 - val_acc: 0.9650\n",
    "// add a convlayer 128 // loss: 0.0484 - acc: 0.9844 - val_loss: 0.0922 - val_acc: 0.9675\n",
    "// add l1 on the first two conv layers //loss: 0.4179 - acc: 0.9839 - val_loss: 0.4799 - val_acc: 0.9775"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
