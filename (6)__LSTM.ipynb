{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import competition dataset\n",
    "x_train = np.load('train_data.npy')\n",
    "y_train = pd.read_csv('train_labels.csv')\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train[:,1]\n",
    "\n",
    "x_test = np.load('test_data.npy')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalization \n",
    "# normalizer = Normalizer().fit(x_train)\n",
    "# x_train = normalizer.transform(x_train)\n",
    "# x_test=normalizer.transform(x_test)\n",
    "\n",
    "# reshape\n",
    "x_train = x_train.reshape(-1,210,210)\n",
    "x_test = x_test.reshape(-1,210,210)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output a 2 dim vector indicating class\n",
    "y_train = np_utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 15:30:14.515105  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0926 15:30:14.557046  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0926 15:30:14.563039  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0926 15:30:19.074234  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0926 15:30:19.169979  1320 deprecation.py:506] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "from keras.layers import LSTM,Flatten,Dense,TimeDistributed, Bidirectional\n",
    "lstmmodel_1 = Sequential()\n",
    "\n",
    "lstmmodel_1.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2,\n",
    "                                   input_shape=(210,210),return_sequences=True),\n",
    "                              input_shape=(210,210)))\n",
    "lstmmodel_1.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2,\n",
    "                                   input_shape=(210,210),return_sequences=True)))\n",
    "\n",
    "\n",
    "lstmmodel_1.add(Flatten())\n",
    "lstmmodel_1.add(Dense(128))\n",
    "lstmmodel_1.add(Dropout(0.5))\n",
    "lstmmodel_1.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 210, 512)          956416    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 210, 256)          656384    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 53760)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               6881408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 8,494,466\n",
      "Trainable params: 8,494,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.summary()\n",
    "lstmmodel_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 15:30:26.587421  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0926 15:30:26.605934  1320 deprecation_wrapper.py:119] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0926 15:30:26.653809  1320 deprecation.py:323] From C:\\Users\\willi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "adam=optimizers.Adam(lr=.0001)\n",
    "lstmmodel_1.compile(loss='binary_crossentropy', \n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3599 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "3599/3599 [==============================] - 2198s 611ms/step - loss: 0.4295 - acc: 0.8594 - val_loss: 0.2994 - val_acc: 0.9150\n",
      "Epoch 2/30\n",
      "3599/3599 [==============================] - 1797s 499ms/step - loss: 0.3465 - acc: 0.8776 - val_loss: 0.2765 - val_acc: 0.9225\n",
      "Epoch 3/30\n",
      "3599/3599 [==============================] - 1855s 516ms/step - loss: 0.2883 - acc: 0.9005 - val_loss: 0.2392 - val_acc: 0.9250\n",
      "Epoch 4/30\n",
      "3599/3599 [==============================] - 1334s 371ms/step - loss: 0.2538 - acc: 0.9172 - val_loss: 0.2414 - val_acc: 0.9375\n",
      "Epoch 5/30\n",
      "3599/3599 [==============================] - 1371s 381ms/step - loss: 0.2212 - acc: 0.9298 - val_loss: 0.2438 - val_acc: 0.9325\n",
      "Epoch 6/30\n",
      "3599/3599 [==============================] - 1361s 378ms/step - loss: 0.2033 - acc: 0.9340 - val_loss: 0.2361 - val_acc: 0.9375\n",
      "Epoch 7/30\n",
      "3599/3599 [==============================] - 1442s 401ms/step - loss: 0.1987 - acc: 0.9386 - val_loss: 0.2351 - val_acc: 0.9350\n",
      "Epoch 8/30\n",
      "3599/3599 [==============================] - 1508s 419ms/step - loss: 0.1745 - acc: 0.9457 - val_loss: 0.2643 - val_acc: 0.9263\n",
      "Epoch 9/30\n",
      "3599/3599 [==============================] - 1569s 436ms/step - loss: 0.1644 - acc: 0.9472 - val_loss: 0.2448 - val_acc: 0.9387\n",
      "Epoch 10/30\n",
      "3599/3599 [==============================] - 411s 114ms/step - loss: 0.1509 - acc: 0.9536 - val_loss: 0.2534 - val_acc: 0.9350\n",
      "Epoch 11/30\n",
      "3599/3599 [==============================] - 449s 125ms/step - loss: 0.1420 - acc: 0.9528 - val_loss: 0.2586 - val_acc: 0.9313\n",
      "Epoch 12/30\n",
      "3599/3599 [==============================] - 490s 136ms/step - loss: 0.1278 - acc: 0.9575 - val_loss: 0.2955 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd3ea59fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "EarlyStopping = EarlyStopping(monitor='val_loss',patience=5,verbose=0,mode='auto')\n",
    "lstmmodel_1.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.1,callbacks=[EarlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_predict= lstmmodel_1.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_predict,columns=['label']).to_csv('submission_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. original//  0.2627 - acc: 0.9434 - val_loss: 0.3483 - val_acc: 0.9271\n",
    "#2 //loss: 0.1336 - acc: 0.9544 - val_loss: 0.2183 - val_acc: 0.9325\n",
    "#3 add another STLM layer (128, 128) //loss: 0.1749 - acc: 0.9415 - val_loss: 0.2377 - val_acc: 0.9375 (interrupt,may even higher)\n",
    "#4 change dense from 32 to 128, filters (256,128) //loss: 0.1278 - acc: 0.9575 - val_loss: 0.2955 - val_acc: 0.9237"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
